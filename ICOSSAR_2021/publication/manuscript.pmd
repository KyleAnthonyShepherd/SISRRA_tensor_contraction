<!---
script to compile pmd into tex and pdf

python ClosePDF.py "ICOSSAR_2021.pdf" && pandoc --from=markdown --output=manuscript.tex manuscript.pmd --columns=40 --wrap=none && lualatex -interaction=nonstopmode ICOSSAR_2021_template.tex & bibtex ICOSSAR_2021_template && D:\Kyle_Shepherd\Documents\Exe_utilities\flatex\flatex.exe ICOSSAR_2021_template.tex && move /y ICOSSAR_2021_template.flt ICOSSAR_2021.tex && lualatex ICOSSAR_2021.tex && lualatex ICOSSAR_2021.tex && start ICOSSAR_2021.pdf
--->

<!---
# Gen Diff

# https://strawberryperl.com/ for latexdiff
pandoc --from=markdown --output=manuscript.tex manuscript_Dec_14_2021_short.pmd --columns=40 --wrap=none && D:\Kyle_Shepherd\Documents\Exe_utilities\flatex\flatex.exe ICOSSAR_2021_Template.tex && move /y ICOSSAR_2021_template.flt ICOSSAR_2021_OLD.tex && latexdiff ICOSSAR_2021_OLD.tex ICOSSAR_2021.tex > ICOSSAR_2021_Diff.tex && lualatex ICOSSAR_2021_Diff.tex && start ICOSSAR_2021_Diff.pdf
--->

# Introduction

## Motivation

Important infrastructure systems such as electrical transmission grids, potable water distribution, and roadway transportation have been modeled as networks for analysis and design \cite{levy1967monte} \cite{cotilla2012comparing}. As these networks grow in size and become more complex, such as the addition of distributed power generation and energy storage in electrical networks \cite{escalera2018survey}, better algorithms are needed to analyze these networks and guarantee their safety and reliability. The tensor network contraction (TNC) algorithm we propose in this work is a step in this direction.

## Problem Definition

A network is a graph consisting of nodes that describe a discrete component of the network (such as a power plant or household) and edges that describe a connection between two nodes (such as power lines or water pipes). We will consider a model of a graph $G = (N,E)$ where $N$ is the set of labeled nodes $n_1,...,n_{|N|}$ and $E$ is the set of labeled edges $e_1,...,e_{|E|}$. Each node $n_i \in N$ has a list of attributes $[S,T]$. In particular, $n_i.S$, the $S$ attribute of variable $n_i$, is a Boolean variable equal to $True$ if $n_i$ is a source node, and $n_i.T$ is a Boolean variable equal to $True$ if $n_i$ is a terminal node. Each edge $e_i \in E$ has a list of attributes $[n_p,n_s,bi,p]$. In particular, $e_i.n_p$ is the predecessor node, $e_i.n_s$ is the successor node, $e_i.bi$ is a Boolean variable equal to $True$ if the edge is bidirectional and $False$ if the edge is directed, and $e_i.p$ is the edge reliability, the probability the edge exists.

To measure graph reliability, we define a function $C(G_r)$, where $C(G_r)=1$ if there is a path from a source node to every terminal node for the particular graph realization $G_r$, indicating a Connected graph, and $C(G_r)=0$ otherwise. A graph realization is defined with a vector $r$ of length $|E|$ where $r_i=1$ if $e_i$ exists, and $r_i=0$ otherwise. The probability of a given graph realization is defined below:
$$P(G_r) = \prod_{i=1}^{|E|} 1-r_i-e_i.p+2*r_i*e_i.p$$
The set of all possible realization vectors is $R$. This set contains $2^{|E|}$ elements.

Reliability is defined as $Rel(G) = \sum_{r \in R} [C(G_r)*P(G_r)]$. $Rel(G)$ will take on a value between 0 and 1, where a higher $Rel(G)$ is desired in practice.

This model as defined allows us to consider two cases of network reliability that are important for managers of infrastructure systems. All Terminal Reliability is $Rel_{ATR}(G)$ where all edges are bidirectional and all nodes are terminal nodes. Source-Terminal reliability is $Rel_{S-T}(G)$ where all edges are directed, and in general the set of source and terminal nodes is much smaller than the set of nodes. For this work, only one source and one terminal node will be considered for $Rel_{S-T}(G)$ (also known as 2-terminal reliability).

## Justification and Objectives

As the time to compute the reliability of a probabilistic graph scales exponentially with the size of the graph \cite{valiant1979complexity}, a naÃ¯ve brute force enumeration of all graph realizations is not feasible for the large graphs frequently encountered in infrastructure systems. Therefore, different approaches are needed to calculate values of $Rel(G)$.

One approach is to develop an algorithm with parameterized complexity to solve $Rel(G)$. While these algorithms may scale exponentially in the worst case, they may not scale as fast for the problems we are interested in. Another approach is to solve a superset problem of $Rel(G)$. In this work, the edge cover problem will be shown to be a superset problem of $Rel_{ATR}(G)$. A final approach is to give up on obtaining an exact answer and instead obtain an approximate answer for $Rel(G)$ using Monte Carlo (MC) simulation.

The objective of this work is to efficiently calculate values of $Rel(G)$ in a principled way. This work will formulate TNC algorithms for exactly solving $Rel_{S-T}(G)$ when the graph is directed and acyclic, and exactly solving an upper bound for $Rel_{ATR}(G)$ by solving the edge cover problem. These proposed TNC algorithms will be shown to have computational complexity parameterized by the treewidth of the graph. The performance of these algorithms will be tested on grid graphs, random cubic graphs, and a selection of real world transmission graphs.

# Background

## Exact Solvers

#### Binary Decision Diagram Methods \

The current state-of-the-art for exactly solving undirected K-Terminal reliability problems (which includes ATR and S-T) is using binary decision diagrams \cite{carlier1996decomposition}. These methods consider one edge at a time, factoring the graph into subgraphs, and pruning by identifying isomorphic graphs \cite{hardy2007k}.

However, the pruning is not very efficient. In the worst case for All Terminal Reliability problems, the number of subgraphs to be considered is proportional to $BELL(F_{max})$, where $BELL(k)$ is the $k^{th}$ bell number and $F_{max}$ is the linear-width, or pathwidth, of the graph. If the pathwidth of the graph is small, this algorithm is still useful, but $BELL(k)>(\frac{k}{e\ln(k)})^k$ \cite{berend2010improved}, growing faster than $2^n$, so binary decision diagram methods quickly become computationally infeasible.

#### #SAT solvers \

The edge cover problem $Rel_{EC}(G)$ is a superset of $Rel_{ATR}(G)$. We can define
$$Rel_{EC}(G) = \sum_{r \in R} [EC(G_r)*P(G_r)]$$
where $EC(G_r)=1$ if every node has at least one existing edge, and $EC(G_r)=0$ otherwise. $Rel_{ATR}(G) \subset Rel_{EC}(G)$ because for every case of $Rel_{ATR}(G)$ every node must have at least one existing edge to ensure connectivity, but $Rel_{EC}(G) \not\subset Rel_{ATR}(G)$ because unconnected "islands" of nodes can satisfy $EC(G_r)$ while not satisfying global connectivity for $C(G_r)$.

Rewritten in conjunctive normal form (CNF) as a monotone #SAT problem \cite{roth1996hardness} \cite{vaisman2015model}:
$$EC(G_r) = \bigwedge_{n_i \in N} (\bigvee_{j \in n_i} e_j(r))$$
where each node $n$ has a set of associated edges $j \in n_i$ if edge $e_j$ has node $n_i$ as a predecessor or successor. The function $e_j(r)$ is equal to True if $r_j=1$ for graph realization $r$.

Our ability to write this problem in CNF form, a set of clauses which all must be true, and each clause is satisfied if at least one variable in the clause is true, allows it to be solved by powerful existing model counting solvers such as cachet \cite{sang2005heuristics}, miniC2D \cite{oztok2015top}, and d4 \cite{lagniez2017improved}. However, these solvers are considered to be "black-box" solvers, so there is no ability to estimate their computation time for an arbitrary graph $G$.

## Probabilistic Solvers

#### Monte Carlo (MC) Methods \

If a set of $K$ independent random realizations of a given graph are generated, $G_{rand}$, then $Rel(G)$ can be estimated from this random sample of graphs. $C(G_{rand})$ can be considered to be a set of Bernoulli trials, a binomial experiment $B(K,p)$ so MC methods can be used to estimate the $p$ of the Bernoulli process and provide a confidence interval.

Given a specific simulation of $G_{rand}$, the log-likelihood profile of $p$ can be obtained. The most likely value of $p$, $p_{true}$, is obtained by finding the maximum of the profile. To obtain a confidence interval, we can use the profile likelihood method \cite{venzon1988method}. For a given desired $1-\alpha$ and $\epsilon=\frac{p_{true}}{p_{-(1-\alpha)\%}}$, the number of needed samples $K$ can be calculated.

For a range of $\epsilon$ values, Figure \ref{fig:MC Trial Graph} shows on a log-log scale how the number of needed MC samples decreases as $p_{true}$ increases. Specifically, if $p_{true}$ increases by a factor of 10, the number of trials needed decreases by a factor of 10 while $p_{true}<0.1$.

\begin{figure}[t]
\caption{Needed MC trials for a given $\epsilon$ at a 95\% confidence interval shown on a log-log scale graph: As $p_{true}$ decreases, the number of needed MC trials for a given relative error increases.}
\label{fig:MC Trial Graph}
\includegraphics[width=0.5\textwidth]{../figures/MCTrials.png}
\end{figure}

The advantage of MC Methods is the number of samples required is only proportional to $\frac{1}{p_{true}}$ and is not proportional to the problem size. The drawback is that $p_{true}$ is not known ahead of time, so the number of samples required could be large if $p_{true}$ is very small and cannot be known ahead of time, and stopping rules must be used, adding uncertainty.

#### Fully Polynomial-time Randomized Approximation Scheme (FPRAS) \

From the analysis above, MC methods become infeasible for estimating graph failure rates when $Rel(G)$ is close to 1. In response to this drawback, Karger \cite{karger2001randomized} developed a Fully Polynomial-time Randomized Approximation Scheme (FPRAS) for estimating $(1-Rel_{ATR}(G))$ that runs in $O(\frac{|E||N|^4}{\epsilon^3}\ln(|N|))$ time.

However, the FPRAS algorithm only works when $(1-Rel_{ATR}(G))<|N|^{-4}$. For most engineering applications, the failure chances we care about are small. For example, 1% for 50 year earthquake hazards \cite{IBC_2017} or $2.0*10^{-6}$ per year for nuclear power plants \cite{NRC_2010}. Therefore, highly reliable engineering networks with more than $(1-2.0*10^{-6})^{-\frac{1}{4}} \approx 27$ nodes cannot be practically solved using known FPRAS methods. In addition, this FPRAS algorithm is limited and only works for All-Terminal Reliability. While extensions exist for K-Terminal problems, such as the one developed by Paredes \cite{paredes2019principled} which works well in practical settings, these extensions rely on NP-oracles and therefore have exponential worst case behavior.

Therefore, we desire an approximation algorithm that is not dependent on $Rel(G)$, and is instead parameterized by some other graph property that is small for engineering networks of interest. TNC algorithms fit this desire, being parameterized by the treewidth of a graph, which is usually small and constrained for the almost-planar engineering networks we care about.

# Tensor Network Contraction (TNC)

## Definitions

The goal of TNC is to write the underlying satisfiability problem as a series of tensor products. Similar techniques have been investigated in the physics community to solve specific quantum mechanics problems \cite{pan2020contracting} \cite{biamonte2019lectures}. Each clause in the satisfiability problem is represented as a tensor $T^c_{x_1,x_2,...,x_k}$. If the variables $x_1,x_2,...,x_k$ satisfy the underlying clause, then $T_{x_1,x_2,...,x_k}=1$. For example, the $T^c$ that encodes the Boolean clause $(x_1 \lor x_2 \lor x_3 \lor x_4)$ is:
\begin{equation*}
T^c_{x_1,x_2,x_3,x_4}=
\begin{cases}
  0, & \text{if}\ x_1=x_2=x_3=x_4=0 \\
  1, & \text{otherwise}
\end{cases}
\end{equation*}

The number of solutions to the satisfiability problem can be calculated by applying the tensor product to every clause tensor $T^c$. The tensor product is defined as
\ten
$$T^p_{x_1,...,x_k,z_1,...,z_k}=T^c_{x_1,...,x_k,y_1,...,y_k} \otimes T^c_{y_1,...,y_k,z_1,...,z_k}$$
\normalsize
where $\otimes$ expands into
\ten
$$T^p_{x_1,...,x_k,z_1,...,z_k}=\sum_{y_i \in Y} \sum_{y_i=0}^{|y_i|} T^c_{x_1,...,x_k,y_1,...,y_k} * T^c_{y_1,...,y_k,z_1,...,z_k}$$
\normalsize
where $Y$ is the set of all variables in common between the two tensors, and $|y_i|$ is the number of states that variable $y_i$ can take. While $y_i$ can take an arbitrary number of states, the remainder of this work will only consider a two-state Boolean variable.

One complication is that a tensor product is only clearly defined if each variable appears exactly once or twice, while in many satisfiability problems a variable can appear more than twice. This complication can be addressed by assigning each $T^c$ a unique set of variables, and then creating additional variable tensors $T^v$ to apply constraints on the variables.

Two common constraints are defined below. To constrain a Boolean variable $x_1$ to take the opposite value of $x_2$ (as needed for a Boolean formula containing $x_1$ and $\neg x_1$), the following tensor $T^v_{x_1,x_2}$ is set as
\begin{equation*}
T^v_{x_1,x_2}=
\begin{cases}
  1, & \text{if}\ x_1=0\ \text{and}\ x_2=1\\
  1, & \text{if}\ x_1=1\ \text{and}\ x_2=0\\
  0, & \text{otherwise}
\end{cases}
\end{equation*}

To constrain a Boolean variable $x_1$ to take the same value of $x_2$ and apply a probability $p$ of both variables being true (as needed to define an unreliable network edge), the tensor $T^v_{x_1,x_2}$ is set as
\begin{equation*}
T^v_{x_1,x_2}=
\begin{cases}
    p, & \text{if}\ x_1=1\ \text{and}\ x_2=1 \\
    1-p, & \text{if}\ x_1=0\ \text{and}\ x_2=0 \\
    0, & \text{otherwise}
\end{cases}
\end{equation*}

## Graph Representation

Tensor multiplications can be represented as a node and edge graph, $G_T$, where each tensor is a node and each variable is an edge. An example of a tensor graph can be seen in Figure \ref{fig:Tensor Graph Example}a. A tensor product can be represented as an edge contraction on this graph. The contraction of edge $X_1$ is visually shown in Figure \ref{fig:Tensor Graph Example}b. Once all edges are contacted, only a scalar value remains, counting the number of solutions to the Boolean problem.

\begin{figure}[t]
\caption{Example Tensor Graph [a] and example tensor contraction of edge $X_1$ [b]}
\label{fig:Tensor Graph Example}
\includegraphics[width=0.5\textwidth]{../figures/TensorGraphExample.png}
\end{figure}

## Contraction Ordering

Care must be taken when choosing the order to perform the edge contractions. Assuming Boolean variables, the product $T^c_{x_1,...,x_n,y_1,...,y_n} \otimes T^c_{y_1,...,y_n,z_1,...,z_n}$ requires $2^{|x|+|y|+|z|}$ multiplications and additions, and $2^{|x|+|z|}$ numbers need to be stored in memory for the resulting tensor. Markov, Igor L and Shi, Yaoyun show how to determine an optimal edge contraction ordering to minimize $|x|$, $|y|$, and $|z|$, also known as elimination ordering, from an optimal tree decomposition of the line graph of $G_T$, $LG(G_T)$ \cite{markov2008simulating}. Dumitrescu et al. \cite{dumitrescu2018benchmarking} demonstrate how algorithms from the PACE 2017 challenge \cite{dell2018pace} can be used to obtain better approximate tree decompositions for some tensor graphs representing quantum many body problems.

Harvey, Daniel J and Wood, David R provide a few different upper bounds for the treewidth of $LG(G_T)$, $tw(LG(G_T))$, bounding the size of the largest tensor \cite{harvey2018treewidth}:
\begin{equation*}
tw(LG(G_T))<(tw(G_T)+1)*D_m(G_T)-1
\end{equation*}
where $D_m(G_T)$ is the maximum degree of graph $G_T$. Dudek et al. \cite{dudek2019efficient} also show how high-rank tensors can be factored into a tensor tree to further minimize memory and computational requirements of the TNC.

Overall, in the worst case for infrastructure networks with bounded max degree (due to physical limitations), the largest number of variables for a single tensor is linearly proportional to the treewidth of $G_T$. Therefore, the computational complexity is at most $2^{C*tw(G)}$, where C is a constant between 1 and $D_m(G_T)$.

For the following formulations, if every variable tensor is contracted into an adjacent clause tensor, the resulting tensor graph is isomorphic to the underlying graph $G$. Therefore, for these formulations, $tw(G_T)$ is equal to $tw(G)$.

## All Terminal Reliability Formulation

For $Rel_{ATR}(G)$ there is no known polynomial sized satisfiability equation, unless auxiliary variables are used \cite{paredes2019principled}. Therefore, a tensor graph for the edge cover problem, $Rel_{EC}(G)$ will be formulated instead. The edge cover problem is satisfied if every node in the graph $G$ has at least one existing edge. Therefore, the clause for a node $n$ with connecting edges $e \in E$ is $(e_1^n \lor e_2^n \lor ... \lor e_i^n)$.

Each edge $e_i$ has a probability $p$ of existing, and each variable $e_i^n$ takes the same correlated state for every superscript $n$. Contracting the tensor graph $G_T$ of these tensors will yield the probability of a satisfying edge cover for the graph $G$.

## S-T Reliability Formulation

For $Rel_{S-T}(G)$, the problem is satisfied if any inbound edge connected to the terminal node $n_t$ is connected to a "marked" node. A node is marked if any of its inbound edges is connected to a "marked" node or a "source" node. For an acyclic directed network, a node $n_b$ is "marked" if and only if there is a path from the source node to node $n_b$ (This statement does not hold true for graphs with cycles). Even in this restricted case, $Rel_{S-T}(G)$ is still a #P-complete problem \cite{provan1986complexity}.

The clause for the terminal node $n_t$ with inbound edges $e \in E$ is $(e_1^{n_t} \lor e_2^{n_t} \lor ... \lor e_i^{n_t})$.

For a node between the source and terminal nodes $n_b$ with inbound edges $e \in E$, it must satisfy the following clause:
\begin{equation*}
\begin{split}
& (m_{n_b} \land (e_1^{n_b} \lor ... \lor e_i^{n_b})) \lor \\
& (\neg m_{n_b} \land \neg (e_1^{n_b} \lor ... \lor e_i^{n_b}))
\end{split}
\end{equation*}
where $m_{n_b}$ is a variable indicating if node $n_b$ is marked.

For each variable $e_i$, it must be constrained to only be True with probability $e_i.p$ when the tail is connected to a "marked" or source node, $m_{n_b}=1$, and always False when the tail is not connected to a "marked" node. Therefore, the corresponding variable tensor for edge $i$ outbound from node $b$ and inbound to node $y$ is:
\begin{equation*}
\begin{split}
& T^{v_e}_{m_{n_{b,y}},e_i^{n_y}}= \\
& \begin{cases}
  e_i.p, & \text{if}\ m_{n_{b,y}}=1\ \text{and}\ e_i^{n_y}=1 \\
  1-e_i.p, & \text{if}\ m_{n_{b,y}}=1\ \text{and}\ e_i^{n_y}=0 \\
  1, & \text{if}\ m_{n_{b,y}}=0\ \text{and}\ e_i^{n_y}=0 \\
  0, & \text{if}\ m_{n_{b,y}}=0\ \text{and}\ e_i^{n_y}=1 \\
\end{cases}
\end{split}
\end{equation*}

In addition, the directed "marked" variable $m_{n_{b,y}}$ must be constrained to the same value as $m_{n_b}$. Contracting the tensor graph $G_T$ of these tensors will yield the exact probability of a satisfying path from the source node to the terminal node for the graph $G$.

## Tensor Network Contraction (TNC) Advantages

TNC algorithms have many advantages over the previously described exact solvers and probabilistic solvers. The upper bound computational complexity of $2^{C*tw(G)}$ is significantly better than the $BELL(Pathwidth(G))$ of the binary decision diagram methods and the unknown upper bounds of the #SAT methods. This bound is not dependent on $Rel(G)$, so TNCs can solve some highly reliable networks faster than probabilistic solvers. The computational effort of a TNC can be known ahead of time (after the approximate tree decomposition), so reliability engineers can confidently choose the most efficient reliability solver algorithm. In addition, for infrastructure networks of interest, they are usually near-planar, which bounds treewidth to $2*\sqrt{6*(k+1)*|N|})$ \cite{dujmovic2017structure} where k is the number of allowed crossings for each edge, and treewidth is frequently lower than this bound \cite{maniu2019experimental}.

TNCs only require vectorized multiplication and addition operations which are very efficient for CPUs and GPUs to compute, while binary decision diagram methods and #SAT methods require many conditional if-then statements which are more difficult to optimize. While probabilistic solvers are perfectly parallel (each sample can be done on a separate computer), the individual tensor contractions can also be broken up and dispatched to multiple parallel computing units.

# Results and Discussion

## Benchmark Graphs

To evaluate the empirical performance of the proposed TNC algorithm, a few classes of graphs will be considered. The first considered class of graphs are grid graphs. As most infrastructure networks are usually near-planar, grid graphs can be considered as the ideal case of planar graphs.

Second, random connected cubic graphs will be considered. Using a set of reliability preserving transformations \cite{shooman1991exact}, and by splitting high degree nodes into a chain of degree 3 nodes connected by unfailing edges, all graphs can be converted to a cubic graph with equivalent $Rel(G)$. A 1-Flipper Markov Chain Monte Carlo (MCMC) algorithm will be used to uniformly generate these random cubic graphs \cite{feder2006local}.

Third, a collection of 58 US power transmission networks \cite{li2016characterizing} will be considered. These graphs will be reduced using reliability preserving transformations before reliability calculations are performed.

All benchmarks are performed on a Intel Core i7-4810MQ CPU @ 2.90GHz, with 16 GB of RAM. All code is single threaded. The code used to generate these graphs can be seen at this link: \url{https://github.com/KyleAnthonyShepherd/SISRRA_tensor_contraction/tree/main/ICOSSAR_2021}

## Grid Graphs

### Computational Time

As seen in Figure \ref{fig:Grid Graph Computational Time}a, as the grid dimension increases, both the number of subgraphs for the binary decision diagram method and the number of floating point operations for the TNC increases exponentially. Figure \ref{fig:Grid Graph Computational Time}b shows the wall clock time taken for each method. In both cases, the slope of the TNC is significantly smaller than the binary decision diagram method, showing significant computational advantages for calculating $EC(G)$ and $Rel_{S-T}(G)$.

Further computational advantages can be seen if one dimension of the grid graph is fixed in size (8 nodes is large enough for a non-trivial treewidth size and small enough to be computed quickly by both methods). As seen in Figure \ref{fig:Grid Graph Computational Time}c, as $n$ increases for the $8xn$ grids, both the number of subgraphs for the binary decision diagram method and the number of floating point operations for the TNC increases linearly. However, as seen in Figure \ref{fig:Grid Graph Computational Time}d, the wall clock time taken for the binary decision diagram method increases quadratically (each subgraph needs an $O(|E|)$ connectivity check) while the TNC time only increases linearly. For graphs of bounded treewidth, TNCs show significant computational improvement.

\begin{figure}[t]
\caption{Computational complexity and wall clock time for $nxn$ and $8xn$ grid graphs. Subgraphs and $REL_{ATR}(G)$ are BDD calculations, and floating point operations and $EC(G)$ are TNC calculations.}
\label{fig:Grid Graph Computational Time}
\includegraphics[width=0.5\textwidth]{../figures/GridGraphComputeTime8.png}
\end{figure}

### Monte Carlo (MC) Comparison

As the TNC only bounds $Rel_{ATR}(G)$ by calculating $EC(G)$, we can evaluate the quality of this estimate by determining the number of MC trials needed to obtain bounds of $Rel_{ATR}(G)$ better than $EC(G)$. Using a 95% confidence interval, we can calculate the number of MC trials needed to create a confidence interval that excludes $EC(G)$.

For an edge failure rate of 0.01, both $Rel_{ATR}(G)$ and $EC(G)$ are approximately constant at 0.9996. Approximately 24 million MC trials are needed to rule out $EC(G)$, and this count is insensitive to the size of the grid. Therefore, for reliable grid graphs, $EC(G)$ is a good bound.

## Random Connected Cubic Graphs

### Computational Time

A random selection of 10,000 random connected cubic graphs $G_{rc}$ from node count $|N|=20$ to $|N|=400$ were generated. The treewidth of $G_{rc}$ and the treewidth of $LG(G_{rc})$ were computed using an approximate treewidth solver \cite{dell2018pace} for 6 seconds. The pathwidth of $G_{rc}$ was estimated from the tree decomposition of $G_{rc}$. As seen in Figure \ref{fig:Random Cubic Treewidth}, there is a linear increase in approximated treewidth as graph size increases.

\begin{figure}[t]
\caption{Approximated treewidth, pathwidth, and treewidth of the line graph of $G_{rc}$ for 10,000 randomly generated connected cubic graphs $G_{rc}$, and the ratios between these widths.}
\label{fig:Random Cubic Treewidth}
\includegraphics[width=0.5\textwidth]{../figures/RcubicWidth_short.png}
\end{figure}

### Monte Carlo (MC) Comparison

A random selection of 10,000 random connected cubic graphs $G_{rc}$ from node count $|N|=20$ to $|N|=50$ were generated and solved for $EC(G)$ and $Rel_{ATR}(G)$. Each edge had a failure rate of 0.01 to represent a network with high reliability. $EC(G)$ is very tightly constrained, with a standard deviation of $1.1*10^{-12}$ for all |N|, and can be estimated as $EC(G) \approx (1-|N|*0.01^3)$. $Rel_{ATR}(G)$ had greater variance, with a range of [0.92265,0.99998].

For each graph, the number of MC trials needed to rule out the $EC(G)$ bound at the 95% confidence interval was calculated. Figure \ref{fig:Random Cubic MC} shows the proportion of cubic graphs that need less than $X$ MC trials to rule out the $EC(G)$ bound. The observed segmented stair-step pattern is unusual, and is likely caused by the graphs in each segment sharing some topological feature such as a bridge.

As graph size increases, the empirical cumulative distribution function pushes up and to the left, indicating more graphs need fewer MC trials to rule out the $EC(G)$ bound. This means as highly reliable cubic graphs become larger, $EC(G)$ becomes a worse bounding value of $Rel_{ATR}(G)$.

\begin{figure}[t]
\caption{The empirical cumulative distribution function of randomly generated connected cubic graphs of size |N| that need less than $X$ MC trials of $Rel_{ATR}(G)$ to rule out the bound from $EC(G)$ at the 95\% confidence level.}
\label{fig:Random Cubic MC}
\includegraphics[width=0.5\textwidth]{../figures/RcubicTrials.png}
\end{figure}

Overall, despite the computational advantages of TNCs, the treewidth of these graphs scales linearly with size, resulting in computational complexity growing exponentially with the size of the graph. In addition, $EC(G)$ as measured by TNCs is a poor bounding value for many cubic graphs, only a few MC trials are needed to achieve a better bounding value. This bounding value becomes worse as the graph size increases.

## Power Transmission Grids

The $Rel_{ATR}(G)$ and $EC(G)$ of 58 transmission power grids \cite{li2016characterizing} were calculated. Table \ref{tab:Power Transmission Grid} shows the node and edge count of these graphs after reliability preserving reductions, and the result of the $Rel_{ATR}(G)$ and $EC(G)$ calculations at edge failure rate 0.5, 0.1 and 0.01. Some graphs were omitted due to trivial structure or inability to compute $Rel_{ATR}(G)$.

Figure \ref{fig:Width Comparison} shows the treewidth and $tw(LG(G))$ of the power grids in relation to the previously analyzed graphs. In general, the treewidth of the power grids is smaller than equal sized cubic graphs, making them very computationally efficient to solve. However, $tw(LG(G))$ of the power grids are significantly greater than their treewidth, comparable to $tw(LG(G_{rc}))$ of equal sized cubic graphs, due to the presence of high degree nodes in the power grids. The tensor factoring techniques in \cite{dudek2019efficient} may reduce these large values of $tw(LG(G))$. Despite this, TNCs still quickly solve $EC(G)$ and $Rel_{S-T}(G)$ of these graphs in comparison to the binary decision diagram techniques.


\begin{figure}[t]
\caption{Treewidth and $tw(LG(G))$ comparison between grid graphs, random cubic graphs, and power transmission grids.}
\label{fig:Width Comparison}
\includegraphics[width=0.5\textwidth]{../figures/WidthCompare.png}
\end{figure}

When each edge only has a 1% chance of failure, $EC(G)$ is a good approximation for 37 of the power grids as seen in the tall green bars in Figure \ref{fig:Power Grid MC}. It would take more than 1,000,000 MC trials to rule out the $EC(G)$ approximation for these graphs. For the largest power grids, only 1,000 MC trials are needed to rule out $EC(G)$.

\begin{figure}[t]
\caption{Number of MC Trials needed to rule out $EC(G)$ at the 95\% confidence level for each power grid at different edge failure rates $p$.}
\label{fig:Power Grid MC}
\includegraphics[width=0.5\textwidth]{../figures/PowerGridMC.png}
\end{figure}

# Conclusion

## Results Summary

Overall, TNCs for solving $Rel_{S-T}(G)$ and estimating $Rel_{ATR}(G)$ demonstrate many computational advantages on many practical networks. These methods are parameterized by the treewidth of the network, so graphs with low treewidth such as grids and the 58 power transmission networks can be quickly solved. In the general case as represented as random cubic graphs, TNCs are not as computationally efficient due to the linear relationship between treewidth and random cubic graph size. In addition, the presence of high degree nodes in the power transmission networks introduces a large constant factor between treewidth and the computationally relevant treewidth of the line graph. Despite these limitations, the tensor methods are still 10 to 100 times faster than the state-of-the-art binary decision diagram methods as measured by wall clock time.

When estimating $Rel_{ATR}(G)$ by calculating $EC(G)$, TNCs show excellent results on grid graphs. As edge failure rate decreases, as is the case for highly reliable networks, $EC(G)$ becomes a better estimator. This increase in estimation accuracy is likely due to the fact that as edge failures become less likely, multiple edge failures needed to disconnect the graph become exponentially less likely, which heavily discounts occurrences of disconnected "islands" of nodes that satisfy $EC(G)$ and do not satisfy $Rel_{ATR}(G)$.

However, $EC(G)$ is only a good estimate for $Rel_{ATR}(G)$ for a small subset of cubic graphs and 37 out of 55 of the power grids. This work did not investigate why $EC(G)$ was a good estimate for these graphs, although it is likely due to topological bottlenecking effects.

## Future Work

In relation to algorithm design, the primary bottleneck to TNCs is the memory requirement. Techniques such as sparse arrays, online matrix compression, or tensor factoring can be used to reduce the memory footprint of large tensors. Additionally, many quantum computer algorithms can be described as tensor contractions \cite{biamonte2017tensor} \cite{duenas2018quantum}, so these TNCs may be able to exploit quantum computers to achieve a quantum speedup over traditional algorithms.

As $EC(G)$ is not always a good approximation for $Rel_{ATR}(G)$, it would be beneficial to classify the graphs where $EC(G)$ is a good approximation of $Rel_{ATR}(G)$. If an algorithm can quickly identify these classes of graphs, then tensor methods can quickly and confidently estimate $Rel_{ATR}(G)$ using $EC(G)$. In addition, determining how to incorporate TNCs with other #SAT solvers into a virtual best solver will greatly expand the classes of graphs where $EC(G)$ can be quickly solved.  

While $Rel_{S-T}(G)$ can be exactly solved by tensor methods for directed acyclic graphs, the introduction of cycles causes drastic multiplicative overcounting of solutions if the given $Rel_{S-T}(G)$ formulation is used. Determining a better tensor graph for solving $Rel_{S-T}(G)$ or determining how to compensate for the multiplicative overcounting can expand the number of graphs that can be exactly solved by TNCs.

\begin{table*}[ht]
\centering
\caption{Power Transmission Network Attributes}
\label{tab:Power Transmission Grid}
\newcolumntype{a}{X}
\newcolumntype{b}{>{\hsize=.33\hsize}X}
\renewcommand{\arraystretch}{.75}
\begin{tabularx}{\textwidth}{bbbbbbaaaaaaaa}
\toprule
ID & |V| & |E| & TW & PW & LGW & $Rel_{time}$ & $Rel_{0.5}$ & $Rel_{0.1}$ & $Rel_{0.01}$ & $EC_{time}$ & $EC_{0.5}$ & $EC_{0.1}$ & $EC_{0.01}$ \tabularnewline
\midrule
\input{../tables/PowerGridsRELTable.tex}
\bottomrule
\end{tabularx}
\end{table*}

